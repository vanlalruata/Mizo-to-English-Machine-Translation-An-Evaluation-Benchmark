# Mizo to English Machine Translation: An Evaluation Benchmark

# Publisher
IEEE

# Autors
Vanlalruata Hnamte and Haulai Thangkhanhau and Jamal Hussain and Chawngthu Lalnunmawii and Laldinsangi Tlaisun and Vanlalruata

# Date of Publication
13 April 2023

# Abstract
Speech is the most natural method for people to convey emotions and communicate. Traditional input techniques are used for machine communication. Communication across distinct regional languages is always unavoidable and takes significant technological effort to make meaningful and effective understanding. Methods of Machine Translation (MT) have been developed in an effort to circumvent this obstacle. Neural Machine Translation (NMT) is one of the projects that has lately seen a significant improvement in terms of human judgement compared to traditional methods such as phrase-based machine translation (PMT) and statistical machine translation (SMT). Therefore, developments in NMT have an influence on the perceived difficulty of humans. Numerous internet translation and mobile application solutions, such as Google Translate, etc., were created to solve this issue. However, such simple translation methods are not accurate for the parallel MizoEnglish languages. In this research, we have attempted to improve language translation by using the superior capacity of NMT to boost the Mizo-to-English translation in the BiLingual Evaluation Understudy (BLEU) measure and achieved 42.65 BLEU Score on the 4 grams. Publicly available Mizo-English corpus was developed.

# Mizo-to-English Parallel Corpus
This Project include Mizo-to-English Parallel Corpus freely.

# Paper Citation:
V. Hnamte, H. Thangkhanhau, J. Hussain, C. Lalnunmawii, L. Tlaisun and Vanlalruata, "Mizo to English Machine Translation: An Evaluation Benchmark," 2022 International Conference on Futuristic Technologies (INCOFT), Belgaum, India, 2022, pp. 1-6, doi: 10.1109/INCOFT55651.2022.10094376.

# DoI
https://doi.org/10.1109/INCOFT55651.2022.10094376

# ResearchGate Link
https://www.researchgate.net/publication/370004855_Mizo_to_English_Machine_Translation_An_Evaluation_Benchmark

# Note:
You may get different result, but, it is all depend on your dataset/corpus. If you find this code and paper useful, kindly consider to cite from your valuable work.
